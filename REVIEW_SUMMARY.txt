================================================================================
                JOINT DERIVATIVE BRANCH - COMPLETE REVIEW
================================================================================

EXECUTIVE SUMMARY:

The joint_derivative branch successfully reduces compilations by 9.1% but 
introduces a 36.6% runtime regression. The optimization works well for 
compute_derivatives() but backfires in Model.d() due to redundant computation.

RECOMMENDATION: Revert Model.d() to single-derivative approach while keeping
the multi-derivative optimization in compute_derivatives().

================================================================================
DETAILED FINDINGS
================================================================================

1. PERFORMANCE METRICS (~/research/frm/danare/main.py)

   Branch              Runtime    Compilations    
   ----------------    --------   --------------
   main                13.63s     132            
   joint_derivative    18.62s     120            
   Difference          +36.6%     -9.1%          

2. CODE REVIEW

   ✅ FunctionBundle.jacobian_fwd_multi()
      - Correct implementation
      - Proper caching by argnums tuple
      - Uses jax.jacfwd(f, argnums=(0,1,2)) to compute multiple derivatives

   ✅ FunctionBundle.jacobian_rev_multi()
      - Mirror of jacobian_fwd_multi with jacrev
      - Also correct

   ✅ Model.d_wrt_multi()
      - Good optimization
      - Efficiently computes only requested derivatives
      - Returns hstack of Jacobians

   ✅ Model.compute_derivatives()
      - Excellent optimization
      - Computes all derivatives in one call
      - This is where the real benefit is

   ⚠️  Model.d()
      - ISSUE 1: Performance regression
        * Computes ALL derivatives but returns only one
        * Called in loops in deterministic.py
        * Example: If called 10 times for different vars with same args,
          computes 10*N derivatives but only uses 10
      
      - ISSUE 2: Indexing bug (latent)
        * Uses jac_tuple[argnum] where argnum is JAX argument number
        * Should use jac_tuple[argnums_list.index(argnum)]
        * Currently works because argnums are always [0,1,2,...]
        * Would fail with non-contiguous argnums like [0,2,5]

3. ROOT CAUSE OF PERFORMANCE REGRESSION

   deterministic.py has patterns like:
   
       tuple(mod.d("transition", var, args) for var in ["u", "x"])
   
   OLD BEHAVIOR (main):
       Call 1: d("transition", "u", args) → compute 1 derivative
       Call 2: d("transition", "x", args) → compute 1 derivative
       Total: 2 derivatives computed
   
   NEW BEHAVIOR (joint_derivative):
       Call 1: d("transition", "u", args) → compute 5 derivatives, return 1
       Call 2: d("transition", "x", args) → compute 5 derivatives, return 1
       Total: 10 derivatives computed (5× waste)
   
   This pattern repeats throughout the deterministic solver, causing the
   36.6% slowdown.

4. WHERE THE OPTIMIZATION WORKS

   compute_derivatives() computes all derivatives at once:
   
       OLD: for var in ["u", "x", "z", "E"]:
                derivatives[var] = d(name, var, args)
            → 4 separate compilations, 4 separate computations
   
       NEW: jac_tuple = jacobian_fwd_multi()(*args)
            for idx, var in enumerate(["u", "x", "z", "E"]):
                derivatives[var] = jac_tuple[idx]
            → 1 compilation, 1 computation of all 4 derivatives
   
   This is a pure win: fewer compilations AND less computation.

================================================================================
RECOMMENDATIONS
================================================================================

OPTION 1: IMMEDIATE FIX (Recommended)
----------
Revert Model.d() to use single derivatives:

    def d(self, name, wrt, *std_args):
        ...
        return bundle.jacobian_fwd_jit[argnum](*std_args)  # OLD CODE

Keep the rest of the changes (d_wrt_multi, compute_derivatives).

Expected result:
  - Compilations: ~125 (still better than main)
  - Runtime: ~13.5s (eliminates regression)
  - Code change: 1 function, low risk

OPTION 2: BETTER FIX (More work)
----------
Add new d_tuple() helper that returns tuple (not hstack):

    def d_tuple(self, name, wrt_list, *std_args):
        argnums = tuple(var_to_argnum[wrt] for wrt in wrt_list)
        return bundle.jacobian_fwd_multi(argnums)(*std_args)

Update deterministic.py to use it:

    # OLD: tuple(mod.d("transition", var, args) for var in ["u", "x"])
    # NEW: mod.d_tuple("transition", ["u", "x"], args)

Expected result:
  - Compilations: ~115 (even better)
  - Runtime: ~12s (faster than main)
  - Code changes: 1 new method + updates to deterministic.py

OPTION 3: FIX BUG ONLY (Not recommended)
----------
Fix indexing bug but keep performance regression:

    argnum_idx = bundle._argnums_list.index(argnum)
    return jac_tuple[argnum_idx]

This fixes correctness but keeps the 36% slowdown.

================================================================================
FILES GENERATED
================================================================================

1. test_joint_derivative.py
   - Demonstrates the indexing bug with non-contiguous argnums
   - Shows it works now only because argnums are always [0,1,2,...]

2. profile_branches.py
   - Automated profiling script comparing both branches
   - Counts compilations and measures runtime

3. joint_derivative_review.md
   - Detailed code review with correctness analysis
   - Explanation of each change

4. performance_analysis.md
   - Deep dive into performance regression
   - Trade-off analysis of compilation vs computation cost

5. recommended_fix.md
   - Complete code for all three fix options
   - Expected results and testing instructions

6. REVIEW_SUMMARY.txt (this file)
   - Executive summary for quick reference

================================================================================
NEXT STEPS
================================================================================

1. Review the findings and choose a fix option

2. If Option 1 (recommended):
   - Revert Model.d() in src/equilibrium/model/model.py
   - Run: python profile_branches.py
   - Verify: compilations ~125, runtime ~13.5s

3. If Option 2 (better but more work):
   - Add d_tuple() method to Model class
   - Update deterministic.py patterns
   - Run: pytest tests/test_deterministic.py
   - Run: python profile_branches.py
   - Verify: compilations ~115, runtime ~12s

4. Consider adding tests for:
   - Non-contiguous argnums (to catch indexing bugs)
   - Performance regression detection
   - Compilation count tracking

================================================================================
CONCLUSION
================================================================================

The joint derivative approach is conceptually sound and provides real benefits
in compute_derivatives(). However, applying it to Model.d() creates a 
performance regression because d() is used in patterns that repeatedly compute
all derivatives but only use one at a time.

The fix is straightforward: use single derivatives in d(), keep multi 
derivatives in compute_derivatives(). This provides the compilation reduction
where it matters while avoiding the computation waste.

For even better results, add a d_tuple() helper and update the deterministic
solver to use it when computing multiple derivatives.

================================================================================
